# halonet-pytorch
Implementation of the Attention layer from the paper, Scaling Local Self-Attention For Parameter Efficient Visual Backbones
